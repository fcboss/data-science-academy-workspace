{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b6b75485105e36c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BLU01 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26d8a5f531043e66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Important Note**\n",
    "\n",
    "When reading files, please use `os.path.join()`. Specially if you are a Windows user!\n",
    "The grader is running on Linux, reading a file my be running locally for you, but then don't run in the grader because of all the weird backslashes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0240afddd4fae69d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import hashlib # for grading purposes\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93e0b4e1a40ebaaa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q1: Use a shell command to keep in 2 variables the first third and the last third of the lines existent in a file\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05a3d2245d57305d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the file data/exercises/elon_musk.txt\n",
    "# Start by counting the total lines and add the total to the variable count_total.  \n",
    "count_total = ! wc -l < data/exercises/elon_musk.txt\n",
    "count_total = int(count_total[0])\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e69c6137e73d90c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '4ec9599fc203d176a301536c2e091a19bc852759b255bd6818810a42c5fed14a'\n",
    "assert hashlib.sha256(str(count_total).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elon Reeve Musk (born June 28, 1971) is a technology entrepreneur, investor, and engineer.',\n",
       " 'He holds South African, Canadian, and U.S. citizenship and is the founder, CEO, and lead designer of SpaceX;co-founder, CEO, and product architect of Tesla, Inc.; co-founder and CEO of Neuralink; founder of The Boring Company;',\n",
       " 'co-founder and co-chairman of OpenAI; and co-founder of PayPal. ',\n",
       " \"In December 2016, he was ranked 21st on the Forbes list of The World's Most Powerful People. He has a net worth of $22.3 billion and is listed by Forbes as the 40th-richest person in the world.\",\n",
       " \"Born and raised in Pretoria, South Africa, Musk moved to Canada when he was 17 to attend Queen's University. \"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ! cat data/exercises/elon_musk.txt\n",
    "text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14cf2619322a8763",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# NOT GRADED optional exercise!!\n",
    "# Now add the first third and the last third of the lines to the variables first_third and last_third. \n",
    "# Make it work to any files using count_total/3 for instance in the bash commands\n",
    "first_third = text[: int(count_total/3)]\n",
    "# YOUR CODE HERE\n",
    "\n",
    "last_third = text[int(count_total/3)]\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6556340d1db98d7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Test the `first_third` and `last_third` exercise by running the following (ungraded) asserts.\n",
    "\n",
    "```\n",
    "assert first_third[-1][0] == 'H'\n",
    "assert last_third[0][0] == 'N'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e27cb8588bb5fd40",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q2: Read a file with specific delimiter\n",
    "\n",
    "Read file **data/exercises/euribor_interest_rates.csv** into a pandas DataFrame.\n",
    "\n",
    "First, you should preview the file using a shell command in order to find out the used delimiter, and other properties of this file.\n",
    "\n",
    "Then, you should use function read_csv to read the data into a DataFrame. The resulting DataFrame should have the last column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head data/exercises/euribor_interest_rates.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-942e0590467e20d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use a shell command to preview the data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Use function read_csv to read the data into a DataFrame\n",
    "df2 = pd.read_csv(\"data/exercises/euribor_interest_rates.csv\", sep= '|', index_col='Years',decimal=',')\n",
    "df2['Euribor 3 months'] = df2['Euribor 3 months'].astype(float)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0c275c9acaa9c74d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df2.loc[2001, 'Euribor 3 months'] == 3.29\n",
    "assert set(df2.columns) == {'Euribor 3 months', 'Euribor 6 months', 'Euribor 12 months'}\n",
    "assert len(df2) == 19\n",
    "assert df2.index[0] == 1999\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df2.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6f9efef818e4a83",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q3: Read a csv file with problems\n",
    "\n",
    "Read file **data/exercises/portugal_urban_waste_per_inhabitant.csv** using function `read_csv`. Pay attention to the following:\n",
    "* you might find some trouble when reading the file, at first, then just ignore the problems ;)\n",
    "* use the first column as index\n",
    "* there are some inputs in the file that should be interpreted as NaN, make sure you select the right one when reading the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat data/exercises/portugal_urban_waste_per_inhabitant.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2771b707556c08d2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 3: expected 3 fields, saw 6\\nSkipping line 30: expected 3 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Urban waste collection per inhabitant (kg/inhabitant)</th>\n",
       "      <th>Selective urban waste collection per inhabitant (kg/inhabitant)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>425.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>357.6</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>352.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>371.7</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>397.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>413.2</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>433.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>457.2</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>454.4</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>441.0</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>448.7</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>445.0</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>451.8</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>465.5</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>471.1</td>\n",
       "      <td>54.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>518.3</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>520.1</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>516.1</td>\n",
       "      <td>76.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>490.4</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>453.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>439.7</td>\n",
       "      <td>56.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>452.9</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>460.4</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>460.9</td>\n",
       "      <td>75.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Urban waste collection per inhabitant (kg/inhabitant)  \\\n",
       "Years                                                          \n",
       "1989                                                 NaN       \n",
       "1991                                               425.7       \n",
       "1992                                                 NaN       \n",
       "1993                                               357.6       \n",
       "1994                                                 NaN       \n",
       "1995                                               352.0       \n",
       "1996                                               371.7       \n",
       "1997                                               397.0       \n",
       "1998                                               413.2       \n",
       "1999                                               433.3       \n",
       "2000                                               457.2       \n",
       "2001                                               454.4       \n",
       "2002                                               441.0       \n",
       "2003                                               448.7       \n",
       "2004                                               445.0       \n",
       "2005                                               451.8       \n",
       "2006                                               465.5       \n",
       "2007                                               471.1       \n",
       "2008                                               518.3       \n",
       "2009                                               520.1       \n",
       "2010                                               516.1       \n",
       "2011                                               490.4       \n",
       "2012                                               453.3       \n",
       "2013                                               439.7       \n",
       "2014                                               452.9       \n",
       "2015                                               460.4       \n",
       "2016                                               460.9       \n",
       "\n",
       "       Selective urban waste collection per inhabitant (kg/inhabitant)  \n",
       "Years                                                                   \n",
       "1989                                                 NaN                \n",
       "1991                                                 1.5                \n",
       "1992                                                 1.7                \n",
       "1993                                                 2.3                \n",
       "1994                                                 NaN                \n",
       "1995                                                 4.0                \n",
       "1996                                                 5.3                \n",
       "1997                                                 6.6                \n",
       "1998                                                 8.1                \n",
       "1999                                                10.6                \n",
       "2000                                                15.3                \n",
       "2001                                                18.3                \n",
       "2002                                                20.4                \n",
       "2003                                                21.7                \n",
       "2004                                                30.5                \n",
       "2005                                                40.5                \n",
       "2006                                                48.1                \n",
       "2007                                                54.6                \n",
       "2008                                                60.3                \n",
       "2009                                                66.5                \n",
       "2010                                                76.2                \n",
       "2011                                                71.4                \n",
       "2012                                                63.3                \n",
       "2013                                                56.3                \n",
       "2014                                                61.4                \n",
       "2015                                                70.8                \n",
       "2016                                                75.1                "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_urban_waste_per_inhabitant.csv with read_csv\n",
    "df3 = pd.read_csv(\"data/exercises/portugal_urban_waste_per_inhabitant.csv\",error_bad_lines=False,index_col='Years',na_values=[\"no-data\",\"999999\"])\n",
    "# YOUR CODE HERE\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-601b354802964776",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df3.loc[1994, 'Urban waste collection per inhabitant (kg/inhabitant)'])\n",
    "assert df3.loc[2011, 'Selective urban waste collection per inhabitant (kg/inhabitant)'] == 71.4\n",
    "\n",
    "mean_selective_waste = df3['Selective urban waste collection per inhabitant (kg/inhabitant)'].mean()\n",
    "assert math.isclose(35.632, mean_selective_waste, rel_tol=1e-3)\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df3.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cfd5a97b1c49a0e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q4: Repair a csv file after importing\n",
    "Read the same file **data/exercises/portugal_urban_waste_per_inhabitant.csv** using function `read_csv`. But now, be sure you don't miss any lines with relevant information! \n",
    "\n",
    "* use csv module to import everything to a list of lists\n",
    "* create a df with only 3 meaningful columns, where the `Years` should be index\n",
    "* replace garbage values with NaN's \n",
    "* format the columns with the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat data/exercises/portugal_urban_waste_per_inhabitant.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-119041388e17fb72",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Urban waste collection per inhabitant (kg/inhabitant)</th>\n",
       "      <th>Selective urban waste collection per inhabitant (kg/inhabitant)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>480.0</td>\n",
       "      <td>78.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>425.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>357.6</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>352.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>371.7</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>397.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>413.2</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>433.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>457.2</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>454.4</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>441.0</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>448.7</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>445.0</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>451.8</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>465.5</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>471.1</td>\n",
       "      <td>54.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>518.3</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>520.1</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>516.1</td>\n",
       "      <td>76.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>490.4</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>453.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>439.7</td>\n",
       "      <td>56.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>452.9</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>460.4</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>460.9</td>\n",
       "      <td>75.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>480.0</td>\n",
       "      <td>78.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Urban waste collection per inhabitant (kg/inhabitant)  \\\n",
       "Years                                                          \n",
       "1989                                                 NaN       \n",
       "1990                                               480.0       \n",
       "1991                                               425.7       \n",
       "1992                                                 NaN       \n",
       "1993                                               357.6       \n",
       "1994                                                 NaN       \n",
       "1995                                               352.0       \n",
       "1996                                               371.7       \n",
       "1997                                               397.0       \n",
       "1998                                               413.2       \n",
       "1999                                               433.3       \n",
       "2000                                               457.2       \n",
       "2001                                               454.4       \n",
       "2002                                               441.0       \n",
       "2003                                               448.7       \n",
       "2004                                               445.0       \n",
       "2005                                               451.8       \n",
       "2006                                               465.5       \n",
       "2007                                               471.1       \n",
       "2008                                               518.3       \n",
       "2009                                               520.1       \n",
       "2010                                               516.1       \n",
       "2011                                               490.4       \n",
       "2012                                               453.3       \n",
       "2013                                               439.7       \n",
       "2014                                               452.9       \n",
       "2015                                               460.4       \n",
       "2016                                               460.9       \n",
       "2017                                               480.0       \n",
       "\n",
       "       Selective urban waste collection per inhabitant (kg/inhabitant)  \n",
       "Years                                                                   \n",
       "1989                                                 NaN                \n",
       "1990                                                78.2                \n",
       "1991                                                 1.5                \n",
       "1992                                                 1.7                \n",
       "1993                                                 2.3                \n",
       "1994                                                 NaN                \n",
       "1995                                                 4.0                \n",
       "1996                                                 5.3                \n",
       "1997                                                 6.6                \n",
       "1998                                                 8.1                \n",
       "1999                                                10.6                \n",
       "2000                                                15.3                \n",
       "2001                                                18.3                \n",
       "2002                                                20.4                \n",
       "2003                                                21.7                \n",
       "2004                                                30.5                \n",
       "2005                                                40.5                \n",
       "2006                                                48.1                \n",
       "2007                                                54.6                \n",
       "2008                                                60.3                \n",
       "2009                                                66.5                \n",
       "2010                                                76.2                \n",
       "2011                                                71.4                \n",
       "2012                                                63.3                \n",
       "2013                                                56.3                \n",
       "2014                                                61.4                \n",
       "2015                                                70.8                \n",
       "2016                                                75.1                \n",
       "2017                                                78.2                "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_urban_waste_per_inhabitant.csv using  \n",
    "f = open(\"data/exercises/portugal_urban_waste_per_inhabitant.csv\",'r')\n",
    "lines = list(csv.reader(f))\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# create a dataframe using the line list with only 3 columns\n",
    "df4 = pd.DataFrame(data=(i[:3] for i in lines[1:]),columns = list(lines)[0])\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#replace invalid values with nan (np.nan)\n",
    "# YOUR CODE HERE\n",
    "df4 =df4.replace({'999999':np.nan,'no-data':np.nan})\n",
    "df4['Years']=df4['Years'].astype(int)\n",
    "df4['Urban waste collection per inhabitant (kg/inhabitant)']=df4['Urban waste collection per inhabitant (kg/inhabitant)'].astype(float)\n",
    "df4['Selective urban waste collection per inhabitant (kg/inhabitant)']=df4['Selective urban waste collection per inhabitant (kg/inhabitant)'].astype(float)\n",
    "\n",
    "#set types per dataframe column\n",
    "# YOUR CODE HERE\n",
    "df4 = df4.set_index('Years')\n",
    "#set a new index to the dataframe\n",
    "# YOUR CODE HERE\n",
    "#lines\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a42299f9047590d5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df4.loc[1994, 'Urban waste collection per inhabitant (kg/inhabitant)'])\n",
    "assert df4.loc[2012, 'Selective urban waste collection per inhabitant (kg/inhabitant)'] == 63.3\n",
    "\n",
    "mean_selective_waste = df4['Selective urban waste collection per inhabitant (kg/inhabitant)'].mean()\n",
    "assert math.isclose(38.78518518518518, mean_selective_waste, rel_tol=1e-3)\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df4.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-389bc42fe462c70e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q5: Read a JSON file\n",
    "\n",
    "Read file **data/exercises/portugal_production_of_electricity_gwh.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat data/exercises/portugal_production_of_electricity_gwh.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c2125479f7e50e5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomass</th>\n",
       "      <th>Geothermal power</th>\n",
       "      <th>Hydropower &lt; 10MW</th>\n",
       "      <th>Hydropower &gt; 10MW</th>\n",
       "      <th>Photovoltaic</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total renewable sources</th>\n",
       "      <th>Windpower</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>988</td>\n",
       "      <td>42</td>\n",
       "      <td>492</td>\n",
       "      <td>7962</td>\n",
       "      <td>1</td>\n",
       "      <td>33264</td>\n",
       "      <td>9501</td>\n",
       "      <td>16</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959</td>\n",
       "      <td>49</td>\n",
       "      <td>658</td>\n",
       "      <td>14207</td>\n",
       "      <td>1</td>\n",
       "      <td>34520</td>\n",
       "      <td>15895</td>\n",
       "      <td>21</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>51</td>\n",
       "      <td>638</td>\n",
       "      <td>12537</td>\n",
       "      <td>1</td>\n",
       "      <td>34207</td>\n",
       "      <td>14301</td>\n",
       "      <td>38</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1022</td>\n",
       "      <td>58</td>\n",
       "      <td>566</td>\n",
       "      <td>12488</td>\n",
       "      <td>1</td>\n",
       "      <td>38984</td>\n",
       "      <td>14224</td>\n",
       "      <td>89</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081</td>\n",
       "      <td>80</td>\n",
       "      <td>589</td>\n",
       "      <td>7042</td>\n",
       "      <td>1</td>\n",
       "      <td>43287</td>\n",
       "      <td>8915</td>\n",
       "      <td>122</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1296</td>\n",
       "      <td>80</td>\n",
       "      <td>675</td>\n",
       "      <td>11040</td>\n",
       "      <td>1</td>\n",
       "      <td>43764</td>\n",
       "      <td>13260</td>\n",
       "      <td>168</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1345</td>\n",
       "      <td>105</td>\n",
       "      <td>770</td>\n",
       "      <td>13605</td>\n",
       "      <td>2</td>\n",
       "      <td>46509</td>\n",
       "      <td>16083</td>\n",
       "      <td>256</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1473</td>\n",
       "      <td>96</td>\n",
       "      <td>706</td>\n",
       "      <td>7551</td>\n",
       "      <td>2</td>\n",
       "      <td>46107</td>\n",
       "      <td>10190</td>\n",
       "      <td>362</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1394</td>\n",
       "      <td>90</td>\n",
       "      <td>891</td>\n",
       "      <td>15163</td>\n",
       "      <td>3</td>\n",
       "      <td>46852</td>\n",
       "      <td>18037</td>\n",
       "      <td>496</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1547</td>\n",
       "      <td>84</td>\n",
       "      <td>577</td>\n",
       "      <td>9570</td>\n",
       "      <td>3</td>\n",
       "      <td>45105</td>\n",
       "      <td>12597</td>\n",
       "      <td>816</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1651</td>\n",
       "      <td>71</td>\n",
       "      <td>381</td>\n",
       "      <td>4737</td>\n",
       "      <td>3</td>\n",
       "      <td>46575</td>\n",
       "      <td>8616</td>\n",
       "      <td>1773</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1704</td>\n",
       "      <td>85</td>\n",
       "      <td>834</td>\n",
       "      <td>10633</td>\n",
       "      <td>5</td>\n",
       "      <td>49041</td>\n",
       "      <td>16187</td>\n",
       "      <td>2926</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1882</td>\n",
       "      <td>201</td>\n",
       "      <td>522</td>\n",
       "      <td>9927</td>\n",
       "      <td>24</td>\n",
       "      <td>47253</td>\n",
       "      <td>16593</td>\n",
       "      <td>4037</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1852</td>\n",
       "      <td>192</td>\n",
       "      <td>517</td>\n",
       "      <td>6781</td>\n",
       "      <td>41</td>\n",
       "      <td>45969</td>\n",
       "      <td>15140</td>\n",
       "      <td>5757</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2087</td>\n",
       "      <td>184</td>\n",
       "      <td>901</td>\n",
       "      <td>8108</td>\n",
       "      <td>160</td>\n",
       "      <td>50207</td>\n",
       "      <td>19017</td>\n",
       "      <td>7577</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2614</td>\n",
       "      <td>197</td>\n",
       "      <td>1088</td>\n",
       "      <td>15459</td>\n",
       "      <td>215</td>\n",
       "      <td>54093</td>\n",
       "      <td>28755</td>\n",
       "      <td>9182</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2923</td>\n",
       "      <td>210</td>\n",
       "      <td>820</td>\n",
       "      <td>11294</td>\n",
       "      <td>282</td>\n",
       "      <td>52465</td>\n",
       "      <td>24691</td>\n",
       "      <td>9162</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2951</td>\n",
       "      <td>146</td>\n",
       "      <td>567</td>\n",
       "      <td>6093</td>\n",
       "      <td>393</td>\n",
       "      <td>46614</td>\n",
       "      <td>20410</td>\n",
       "      <td>10260</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3051</td>\n",
       "      <td>197</td>\n",
       "      <td>1167</td>\n",
       "      <td>13701</td>\n",
       "      <td>479</td>\n",
       "      <td>51673</td>\n",
       "      <td>30610</td>\n",
       "      <td>12015</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3049</td>\n",
       "      <td>205</td>\n",
       "      <td>1341</td>\n",
       "      <td>15071</td>\n",
       "      <td>627</td>\n",
       "      <td>52802</td>\n",
       "      <td>32405</td>\n",
       "      <td>12111</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3104</td>\n",
       "      <td>204</td>\n",
       "      <td>752</td>\n",
       "      <td>9048</td>\n",
       "      <td>799</td>\n",
       "      <td>52423</td>\n",
       "      <td>25514</td>\n",
       "      <td>11608</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3070</td>\n",
       "      <td>172</td>\n",
       "      <td>1221</td>\n",
       "      <td>15689</td>\n",
       "      <td>822</td>\n",
       "      <td>60279</td>\n",
       "      <td>33448</td>\n",
       "      <td>12474</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3220</td>\n",
       "      <td>217</td>\n",
       "      <td>623</td>\n",
       "      <td>7009</td>\n",
       "      <td>992</td>\n",
       "      <td>59432</td>\n",
       "      <td>24309</td>\n",
       "      <td>12248</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Biomass  Geothermal power  Hydropower < 10MW  Hydropower > 10MW  \\\n",
       "0       988                42                492               7962   \n",
       "1       959                49                658              14207   \n",
       "2      1036                51                638              12537   \n",
       "3      1022                58                566              12488   \n",
       "4      1081                80                589               7042   \n",
       "5      1296                80                675              11040   \n",
       "6      1345               105                770              13605   \n",
       "7      1473                96                706               7551   \n",
       "8      1394                90                891              15163   \n",
       "9      1547                84                577               9570   \n",
       "10     1651                71                381               4737   \n",
       "11     1704                85                834              10633   \n",
       "12     1882               201                522               9927   \n",
       "13     1852               192                517               6781   \n",
       "14     2087               184                901               8108   \n",
       "15     2614               197               1088              15459   \n",
       "16     2923               210                820              11294   \n",
       "17     2951               146                567               6093   \n",
       "18     3051               197               1167              13701   \n",
       "19     3049               205               1341              15071   \n",
       "20     3104               204                752               9048   \n",
       "21     3070               172               1221              15689   \n",
       "22     3220               217                623               7009   \n",
       "\n",
       "    Photovoltaic  Total  Total renewable sources  Windpower  Year  \n",
       "0              1  33264                     9501         16  1995  \n",
       "1              1  34520                    15895         21  1996  \n",
       "2              1  34207                    14301         38  1997  \n",
       "3              1  38984                    14224         89  1998  \n",
       "4              1  43287                     8915        122  1999  \n",
       "5              1  43764                    13260        168  2000  \n",
       "6              2  46509                    16083        256  2001  \n",
       "7              2  46107                    10190        362  2002  \n",
       "8              3  46852                    18037        496  2003  \n",
       "9              3  45105                    12597        816  2004  \n",
       "10             3  46575                     8616       1773  2005  \n",
       "11             5  49041                    16187       2926  2006  \n",
       "12            24  47253                    16593       4037  2007  \n",
       "13            41  45969                    15140       5757  2008  \n",
       "14           160  50207                    19017       7577  2009  \n",
       "15           215  54093                    28755       9182  2010  \n",
       "16           282  52465                    24691       9162  2011  \n",
       "17           393  46614                    20410      10260  2012  \n",
       "18           479  51673                    30610      12015  2013  \n",
       "19           627  52802                    32405      12111  2014  \n",
       "20           799  52423                    25514      11608  2015  \n",
       "21           822  60279                    33448      12474  2016  \n",
       "22           992  59432                    24309      12248  2017  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_production_of_electricity_gwh.json with read_json\n",
    "df5 = pd.read_json(\"data/exercises/portugal_production_of_electricity_gwh.json\", orient='index')\n",
    "# YOUR CODE HERE\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f085fa2cdad9319",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df5) == 23\n",
    "assert set(df5.columns) == {'Biomass', 'Geothermal power', 'Hydropower < 10MW', 'Hydropower > 10MW', \n",
    "                           'Photovoltaic', 'Total','Total renewable sources','Windpower','Year'}\n",
    "\n",
    "expected_hash = 'c8226c54f1a24ae847c02a3e7a7d6e9fb44c2f82eb6f1fddcee9092c434e67fb'\n",
    "assert hashlib.sha256(str(df5.loc[:,'Hydropower > 10MW'].sum()).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d4b970f55b3e427",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q6: Read an Excel file\n",
    "\n",
    "Read file **data/exercises/portugal_gas_emissions_per_year.xlsx** using function read_excel. Pay attention to the following:\n",
    "\n",
    "* you should grab the table \"Series\" in sheet \"Metadata\"\n",
    "* use column 'Serie' as index\n",
    "* make sure you keep only the rows with data\n",
    "* set the variable distinct_scales with the number of ... distinct scales found in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-017a7c31b0ddc38e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_gas_emissions_per_year.xlsx with read_excel\n",
    "df6 = pd.read_excel(\n",
    "    \"data/exercises/portugal_gas_emissions_per_year.xlsx\",\n",
    "    sheet_name=\"Metadata\",\n",
    "    index_col=\"Serie\",\n",
    "     skiprows=22,\n",
    "\n",
    "#     skipfooter=3\n",
    ")# YOUR CODE HER\n",
    "df6 = df6.dropna(axis=0,how='all')\n",
    "distinct_scales = 2\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-91d5f07e40585680",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert distinct_scales == 2\n",
    "assert isinstance(df6, pd.DataFrame)\n",
    "expected_hash = '60c3ad36f77e7366103fe36a3f551a0cde7d64e26d3102ddb8b953d6208a6006'\n",
    "assert hashlib.sha256(\n",
    "        df6.loc[\n",
    "            df6.index==\"Nitrogen oxides\", \n",
    "            \"Measure Unit\"][0].encode()\n",
    "    ).hexdigest() == expected_hash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a7407517d4d92c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q7: Find the encoding of a file\n",
    "\n",
    "Find the encoding used in file **data/exercises/cities.csv**, using the method that was shown in the Learning Units.\n",
    "\n",
    "Then, read the data into a DataFrame, using the read_csv method and find the `City` characters that has distance equal to 7503."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd6944fd63bb38d8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the encoding of file data/exercises/mystery_cities.csv\n",
    "encoding = chardet.detect(open(\"data/exercises/cities.csv\", 'rb').read())['encoding']\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Read the file into a DataFrame\n",
    "df7 = pd.read_csv(\"data/exercises/cities.csv\", encoding='IBM866')\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Find the name of the city with distance = 7503\n",
    "city_found = df7.loc[3]['City']\n",
    "# YOUR CODE HERE\n",
    "city_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-687fb83c97e03355",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df7, pd.DataFrame)\n",
    "\n",
    "expected_hash_1 = '969aef39a1d4cb1c5928c774cd7a4e3ccfc064a18fbd43a70193a2631d8a122d'\n",
    "assert hashlib.sha256(encoding.encode()).hexdigest() == expected_hash_1\n",
    "\n",
    "expected_hash_2 = '8086d7adc029756c1b9094df64f6e79017dcc5a99c3c5e55b47beede11179a2b'\n",
    "assert hashlib.sha256(city_found.encode()).hexdigest() == expected_hash_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d103dfae3d5e11fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q8: Import a Random Sample of a Big File\n",
    "\n",
    "Consider the file **data/exercises/world_percentage_of_literacy.tsv**. Let's imagine this file is really huge, with a lot of rows!  Read the file using a random sample of 7 rows. Count the actual lines with `wc` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat data/exercises/world_percentage_of_literacy.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb39107093dd73fb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv with wc and save the number of lines\n",
    "# in lines_in_file. Notice that the header is not a line..\n",
    "# don't forget to close the opened file\n",
    "# YOUR CODE HERE\n",
    "lines_in_file = ! wc -l < data/exercises/world_percentage_of_literacy.tsv\n",
    "lines_in_file = int(lines_in_file[0]) -1\n",
    "# make parameter rows_to_skip equal to the lines you want to skip loading \n",
    "# don't forget: \n",
    "# - 7 rows should be fecthed)\n",
    "# - you want to keep the header plus 7 rows in the new dataframe...\n",
    "n_rows_to_skip = lines_in_file - 7\n",
    "\n",
    "rows_to_skip = random.sample(\n",
    "    range(1, lines_in_file-1), # this is a range from the first row after the header, to the last row on the file\n",
    "    n_rows_to_skip # this is the number of rows we want to sample, i.e, to skip\n",
    ")\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create a df8 file with the sampled values\n",
    "# YOUR CODE HERE\n",
    "df8 = pd.read_csv(\"data/exercises/world_percentage_of_literacy.tsv\",sep='\\t',skiprows=rows_to_skip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec15a8be42137a01",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# getting remaining list of countries, removing rows_to_skip from the file\n",
    "df_helper = pd.read_csv( \n",
    "    'data/exercises/world_percentage_of_literacy.tsv', \n",
    "    sep='\\t',\n",
    "    header=0 \n",
    ")\n",
    "\n",
    "total_indexes = list(df_helper.index)\n",
    "for s in rows_to_skip:\n",
    "    total_indexes.remove(s-1)\n",
    "\n",
    "assert lines_in_file==194\n",
    "assert isinstance(df8, pd.DataFrame)\n",
    "assert list(df8['Country'])==list(df_helper.iloc[total_indexes]['Country'])\n",
    "assert df8.shape[0]==7\n",
    "\n",
    "expected_hash = '7902699be42c8a8e46fbbb4501726517e86b22c56a189f7625a6da49081b2451'\n",
    "assert  hashlib.sha256(str(df8.shape[0]).encode()).hexdigest() == expected_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f87e07a7b2cacd9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q9: Loading a Big File\n",
    "\n",
    "Read file **data/exercises/world_percentage_of_literacy.tsv** using chunks keep only the columns `Country` and `Literacy rate (all)`.\n",
    "Note that:\n",
    "* file should be read by chunks of 10 countries\n",
    "* the missing values should be removed (filtered in each chunk)\n",
    "* the `Literacy rate (all)` should be converted to type float (in each chunk)\n",
    "* the index should be incremental starting from 0 (i.e, you don't need to read any column as the index)\n",
    "\n",
    "In the end calculate the average `Literacy rate (all)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5106c25a705296e8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the chunks should be appended in a list called chunk_arr\n",
    "# YOUR CODE HERE\n",
    "chunks_iter = pd.read_csv(\"data/exercises/world_percentage_of_literacy.tsv\",sep='\\t', chunksize = 10)\n",
    "chunk_arr = []\n",
    "mean_arr = []\n",
    "for data_chunk in chunks_iter:\n",
    "\n",
    "    #print(data_chunk['Literacy rate (all)'].value_counts())\n",
    "    \n",
    "    data_chunk['Literacy rate (all)'] = data_chunk['Literacy rate (all)'].replace('not reported by UNESCO 2015',np.nan)\n",
    "\n",
    "    #print(data_chunk)\n",
    "    \n",
    "    data_chunk = data_chunk[['Country','Literacy rate (all)']].dropna(how='any')\n",
    "\n",
    "    data_chunk['Literacy rate (all)'] = data_chunk['Literacy rate (all)'].str.replace('%','')\n",
    "    data_chunk['Literacy rate (all)'] = data_chunk['Literacy rate (all)'].str.split('[').str.get(0)\n",
    "    data_chunk['Literacy rate (all)'] = data_chunk['Literacy rate (all)'].str.split(' ').str.get(0)\n",
    "\n",
    "    data_chunk['Literacy rate (all)']=data_chunk['Literacy rate (all)'].astype(float)\n",
    "    #print(data_chunk)\n",
    "\n",
    "    chunk_arr.append(data_chunk)\n",
    "    mean_arr.append(data_chunk['Literacy rate (all)'].mean())\n",
    "# df9 should be the final dataframe with concatenated chunks\n",
    "# Resulting average should go on lit_avg variable\n",
    "# YOUR CODE HERE\n",
    "df9 = pd.concat(chunk_arr, axis=0)\n",
    "weights=list((len(c) for c in chunk_arr))\n",
    "lit_avg = df9['Literacy rate (all)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f60a22c3465d5b83",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df9.loc[df9['Country']=='World', 'Literacy rate (all)'].values[0] == 86.3\n",
    "assert df9.dtypes['Country'] == np.object\n",
    "assert df9.dtypes['Literacy rate (all)'] == np.float\n",
    "\n",
    "expected_hash = 'f26cd8ca964afd7aaaea0cacb142419676cf9928772f5b5310a036ffdae1586a'\n",
    "assert hashlib.sha256(str([len(c) for c in chunk_arr]).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '94f2bba3a658b5642ebbc9b952af45c3db1a185ae0357e4fe7ced784f0c3fe29'\n",
    "assert hashlib.sha256(str(lit_avg).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e990312f7cddd0b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q10: Calculate average values using chunks and avoiding a complete data frame in memory.\n",
    "\n",
    "Using chunks, read file **data/exercises/world_percentage_of_literacy.tsv**, avoid incompleted rows and calculate the average of ***Literacy rate (all)*** without loading all data simultaneously. Use a similar approach of the previous question but don't create any dataframe neither any list with chunks;\n",
    "\n",
    "***Hint: Use the average definition***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57fd7700885246eb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the final average should be in the variable final_avg\n",
    "# You should increment 2 variables in each chunk and use them at the end to calculate final_avg. call them lit_a, lit_b\n",
    "# YOUR CODE HERE\n",
    "lit_a=(np.dot(list(mean_arr),list(weights)))\n",
    "final_avg = np.average(mean_arr,weights=list(len(c) for c in chunk_arr))\n",
    "lit_b=sum(list(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0edcf1260d7886c9",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(83.24370860927154, final_avg, rel_tol=1e-1)\n",
    "assert lit_b==151 or lit_a==151\n",
    "assert int(lit_b) == 12569 or int(lit_a)==12569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
