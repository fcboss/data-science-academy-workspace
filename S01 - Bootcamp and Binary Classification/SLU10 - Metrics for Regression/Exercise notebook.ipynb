{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68fa160327bd350b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SLU10 - Metrics for Regression: Exercise Notebook\n",
    "\n",
    "In this notebook, you will implement:\n",
    "    - Mean Absolute Error (MAE)\n",
    "    - Mean Squared Error (MSE)\n",
    "    - Root Mean Squared Error (RMSE)\n",
    "    - Coefficient of Determination (R²)\n",
    "    - Adjusted R²\n",
    "    - Scikitlearn metrics\n",
    "    - Using metrics for k-fold cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-517511ad73591944",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Start by loading the data we will use to fit a linear regression - hopefully you still have SLU07 in your memory - and fitting the LinearRegression estimator from scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c3b5b62586587194",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "x = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = pd.Series(data['target'])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7aed052cfe019718",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x_housing = x.values\n",
    "y_housing = y.values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_housing, y_housing)\n",
    "\n",
    "y_hat_housing = lr.predict(x_housing)\n",
    "betas_housing = pd.Series([lr.intercept_] + list(lr.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec6525e56e745670",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1 Metrics\n",
    "\n",
    "We will start by covering the metrics we learned in the unit, in particular a set of related metrics:\n",
    "\n",
    "- Mean Absolute Error\n",
    "\n",
    "$$MAE = \\frac{1}{N} \\sum_{n=1}^N \\left| y_n - \\hat{y}_n \\right|$$\n",
    "\n",
    "\n",
    "- Mean Squared Error\n",
    "\n",
    "$$MSE = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2$$\n",
    "\n",
    "\n",
    "- Root Mean Squared Error\n",
    "\n",
    "$$RMSE = \\sqrt{MSE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4277453d93ffea7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Mean Absolute Error\n",
    "\n",
    "Implement the Mean Absolute Error in the function below. \n",
    "\n",
    "**NOTE**: Notice that we've added a variable to get the sign of the error. This is just a sanity check for the function and is not necessary for the implementation, so do not worry about it and just implement each step as stated in the comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4959a7de3c3ad479",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        mae : float with Mean Absolute Error\n",
    "        sn_check : integer with sign of sum of errors for sanity check in tests\n",
    "    \"\"\"\n",
    "    # 1) Compute the error.\n",
    "    # error = ...\n",
    "    # YOUR CODE HERE\n",
    "    error= y-y_pred    \n",
    "    # 2) Compute the absolute value of the errors for each sample\n",
    "    # abs_error = ...\n",
    "    # YOUR CODE HERE\n",
    "    abs_error = np.abs(error)\n",
    "    \n",
    "    # 3) Compute the mean of the absolute value of the errors\n",
    "    mae = abs_error.mean()\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    sn_check = np.sign(np.sum(error))\n",
    "    return mae, sn_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bc5a8e9de443554",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Check the outputs of your function match the results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-41455e2d039c8354",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "mae, error_sgn = mean_absolute_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.20867273347264428, mae)\n",
    "assert error_sgn == -1\n",
    "\n",
    "np.random.seed(59)\n",
    "mae, error_sgn = mean_absolute_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.2578130479011501, mae)\n",
    "assert error_sgn == -1\n",
    "\n",
    "np.random.seed(5123)\n",
    "mae, error_sgn = mean_absolute_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.30802805261201044, mae)\n",
    "assert error_sgn == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15730aedeb842b6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now compute the Mean Absolute Error for our housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73bd9d0135f4badd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Housing dataset: 3.270862810900312\n"
     ]
    }
   ],
   "source": [
    "MAE, _ = mean_absolute_error(y_hat_housing, y_housing)\n",
    "print('Mean Absolute Error Housing dataset: {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e19afebf9f22bab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Mean Squared Error\n",
    "\n",
    "Now implement the mean squared error in the next function:\n",
    "\n",
    "**NOTE**: Once again, ignore the sanity check in the return of the function and just implement each step as stated in the comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7a35367fa5f0f10",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        mse : float with Mean Squared Error Value\n",
    "        sn_check : integer with sign of sum of errors for sanity check in tests\n",
    "\n",
    "    \"\"\"\n",
    "    # 1) Compute the error.\n",
    "    # error = ...\n",
    "    # YOUR CODE HERE\n",
    "    error = y-y_pred\n",
    "    \n",
    "    # 2) Compute the squared value of the errors for each sample\n",
    "    # squared_error = ...\n",
    "    # YOUR CODE HERE\n",
    "    squared_error = np.square(error)\n",
    "    \n",
    "    # 3) Compute the mean squared value of the errors\n",
    "    # mae = ...\n",
    "    # YOUR CODE HERE\n",
    "    mse = squared_error.mean()\n",
    "    \n",
    "    sn_check = np.sign(np.sum(error))\n",
    "    return mse, sn_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb656ddb462c6d28",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Check the outputs of your function match the results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8ea8afca85e2b4bd",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "mse, error_sgn = mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.066594135739203, mse)\n",
    "assert error_sgn == -1\n",
    "\n",
    "np.random.seed(59)\n",
    "mse, error_sgn = mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.08125397072395174, mse)\n",
    "assert error_sgn == -1\n",
    "\n",
    "np.random.seed(5123)\n",
    "mse, error_sgn = mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.11729730659887387, mse)\n",
    "assert error_sgn == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b8f08b7035e6e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now compute the Mean Squared Error for our housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73cca7bee0c9669f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Housing dataset: 21.894831181729206\n"
     ]
    }
   ],
   "source": [
    "MSE, _ = mean_squared_error(y_hat_housing, y_housing)\n",
    "print('Mean Squared Error Housing dataset: {}'.format(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6d6fa40bc386a18f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Root Mean Squared Error\n",
    "\n",
    "Finally, implement the root mean squared error in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-116b13594e8c311c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    # 1) Compute the mean squared error. Tip: don't forget our previous function\n",
    "    # returned an extra output value:\n",
    "    # mse, _ = ...\n",
    "    # YOUR CODE HERE\n",
    "    mse,_ = mean_squared_error(y_pred, y)\n",
    "    \n",
    "    # 2) Compute the root square.\n",
    "    rmse  =np.sqrt(mse)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ba1a1df9f8b9691",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Check the outputs of your function match the results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-774c0900c5f9193c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rmse = root_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.25805839598665065, rmse)\n",
    "\n",
    "np.random.seed(59)\n",
    "rmse = root_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.2850508213002582, rmse)\n",
    "\n",
    "np.random.seed(5123)\n",
    "rmse = root_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.3424869436911046, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be57a05f0542667b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finally, compute the Root Mean Squared Error for our housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-958187135a37601f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error Housing dataset: 4.679191295697282\n"
     ]
    }
   ],
   "source": [
    "RMSE = root_mean_squared_error(y_hat_housing, y_housing)\n",
    "print('Root Mean Squared Error Housing dataset: {}'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7247af52a77608d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Nest we will focus on the Coefficient of Determination - $R^2$ - and its adjusted form. See the equations below:\n",
    "\n",
    "- $R^2$ score \n",
    "\n",
    "$$R² = 1 - \\frac{MSE(y, \\hat{y})}{MSE(y, \\bar{y})} \n",
    "= 1 - \\frac{\\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2}{\\frac{1}{N} \\sum_{n=1}^N (y_n - \\bar{y})^2}\n",
    "= 1 - \\frac{\\sum_{n=1}^N (y_n - \\hat{y}_n)^2}{\\sum_{n=1}^N (y_n - \\bar{y})^2}$$\n",
    "\n",
    "where $$\\bar{y} = \\frac{1}{N} \\sum_{n=1}^N y_n$$\n",
    "\n",
    "- Adjusted $R^2$ score \n",
    "\n",
    "$$\\bar{R}^2 = 1 - \\frac{N - 1}{N - K - 1} (1 - R^2)$$\n",
    "\n",
    "where $N$ is the number of observations in the dataset used for training the model (i.e. number of rows of the pandas dataframe) and $K$ is the number of features used by your model (i.e. number of columns of the pandas dataframe)\n",
    "\n",
    "\n",
    "### 1.4 R² score\n",
    "\n",
    "Start by implementing the $R^2$ score in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51f11aef440a31c5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def r_squared(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        r2 : float with R squared value\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Compute labels mean.\n",
    "    # y_mean = ...\n",
    "    # YOUR CODE HERE\n",
    "    y_mean = y.mean()\n",
    "\n",
    "    # 2) Compute the mean squared error between the target and the predictions.\n",
    "    # Tip: don't forget our previous function returned an extra output value:\n",
    "    mse_pred, _ = mean_squared_error(y_pred, y)\n",
    "    \n",
    "    \n",
    "    # 3) Compute the mean squared error between the target and its mean.\n",
    "    # Tip: don't forget our previous function returned an extra output value:\n",
    "    # mse_mean, _ = ...\n",
    "    # YOUR CODE HERE\n",
    "    mse_mean,_ = mean_squared_error(y_mean, y)\n",
    "    \n",
    "    # 4) Finally, compute R²\n",
    "    r2 = 1- mse_pred/mse_mean\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1063e13d06463111",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Check the outputs of your function match the results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7fb94c0cc204ea9b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "r2 = r_squared(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.19069113996339448, r2)\n",
    "\n",
    "np.random.seed(59)\n",
    "r2 = r_squared(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(-1.8824436011394203, r2)\n",
    "\n",
    "np.random.seed(5123)\n",
    "r2 = r_squared(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(-1.360482238317167, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70e7964ece7ca6e2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now compute the $R^2$ metric for our housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8edd57ce8cf12b55",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Housing dataset: 0.7406426641094094\n"
     ]
    }
   ],
   "source": [
    "r2 = r_squared(y_hat_housing, y_housing)\n",
    "print('R² Housing dataset: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e5687e52ae19a518",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.5 Adjusted R² score\n",
    "\n",
    "Then implement the adjusted $R^2$ score in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b35baba302fa675b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def adjusted_r_squared(y_pred, y, K):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        K : integer - Number of features used in the model that computed y_hat.\n",
    "\n",
    "    Returns: \n",
    "        r2_adj : float with adjusted R squared value\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Compute R².\n",
    "    r2 = r_squared(y_pred, y,)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    # 2) Get number of samples \n",
    "    N = y.shape[0]\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # 3) Adjust R²\n",
    "    r2_adj = 1- (N-1)*(1-r2)/(N-K-1)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return r2_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32b7193c2bd18cd3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Check the outputs of your function match the results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2f310b9310e8fc38",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 2)\n",
    "assert math.isclose(-0.04053996290420714, r2)\n",
    "\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 4)\n",
    "assert math.isclose(-0.6991107774718119, r2)\n",
    "\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 6)\n",
    "assert math.isclose(-4.233753434084596, r2)\n",
    "\n",
    "\n",
    "np.random.seed(59)\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 2)\n",
    "assert math.isclose(-2.7059989157506834, r2)\n",
    "\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 4)\n",
    "assert math.isclose(-6.335063758394579, r2)\n",
    "\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 6)\n",
    "assert math.isclose(-5.7724000351424, r2)\n",
    "\n",
    "\n",
    "np.random.seed(5123)\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 2)\n",
    "assert math.isclose(-2.034905734979215, r2)\n",
    "\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 4)\n",
    "assert math.isclose(-3.2349529047632934, r2)\n",
    "\n",
    "r2 = adjusted_r_squared(np.random.rand(10), np.random.rand(10), 6)\n",
    "assert math.isclose(-9.461284010320593, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6addd87af835f826",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finally compute the adjusted $R^2$ metric for our housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3c74c33f25a842f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R² Housing dataset: 0.7337897263724629\n"
     ]
    }
   ],
   "source": [
    "r2 = adjusted_r_squared(y_hat_housing, y_housing, x_housing.shape[1])\n",
    "print('Adjusted R² Housing dataset: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-56bdb7b77c9bc15b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2 ScikitLearn metrics\n",
    "\n",
    "As you know, scikitlearn also already provides you with implementations of these metrics: \n",
    "\n",
    "- `sklearn.metrics.mean_absolute_error`\n",
    "- `sklearn.metrics.mean_squared_error`\n",
    "- `sklearn.metrics.r2_score`\n",
    "- `sklearn.linear_model.LinearRegression.score` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f974da1ba19fbc4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Import sklearn metrics\n",
    "from sklearn import metrics as sklearn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-649d810401fbc558",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.1 Mean absolute error\n",
    "\n",
    "Start by implementing below the mean absolute error function with scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44133719d81f028a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sklearn_mean_absolute_error(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        mae : float with Mean Absolute Error\n",
    "    \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "    return sklearn_metrics.mean_absolute_error(y,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e82dbfd0989d4ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Make sure your function passes the tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f2df280b0527d9e1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "mae = sklearn_mean_absolute_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.20867273347264428, mae)\n",
    "\n",
    "np.random.seed(5123)\n",
    "mae = sklearn_mean_absolute_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.30802805261201044, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c80d8cb59ab1e49e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.2 Mean squared error and Root Mean Squared Error\n",
    "\n",
    "Implement the mean squared error and root mean squared error functions below with scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91685e84daf075d0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sklearn_mean_squared_error(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        mae : float with Mean Squared Error\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return sklearn_metrics.mean_squared_error(y,y_pred)\n",
    "    \n",
    "\n",
    "def sklearn_root_mean_squared_error(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        mae : float with Root Mean Squared Error\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return np.sqrt(sklearn_metrics.mean_squared_error(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44bf1a140786fac4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Make sure your function passes the tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-bb0647e6f49b6b36",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "mse = sklearn_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.066594135739203, mse)\n",
    "\n",
    "np.random.seed(59)\n",
    "mse = sklearn_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.08125397072395174, mse)\n",
    "\n",
    "np.random.seed(42)\n",
    "rmse = sklearn_root_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.25805839598665065, rmse)\n",
    "\n",
    "np.random.seed(5123)\n",
    "rmse = sklearn_root_mean_squared_error(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(0.3424869436911046, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-483ede84836e8211",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.3  R² score and Adjusted R² score\n",
    "\n",
    "Implement the R² score and adjusted R² score below using scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc8ebf5c8c8c6e23",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sklearn_r_squared(y_pred, y): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        \n",
    "    Returns: \n",
    "        r2 : float with R squared value\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return sklearn_metrics.r2_score(y,y_pred)\n",
    "    \n",
    "\n",
    "def sklearn_adjusted_r_squared(y_pred, y, K): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y_pred : numpy.array with shape (num_samples,) - predictions\n",
    "        y : numpy.array with shape (num_samples,) - labels \n",
    "        K : integer - Number of features used in the model that computed y_hat.\n",
    "\n",
    "    Returns: \n",
    "        r2_adj : float with adjusted R squared value\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    N = y.shape[0]\n",
    "    r2 = sklearn_metrics.r2_score(y,y_pred)\n",
    "    \n",
    "    return 1- (N-1)*(1-r2)/(N-K-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df5035b5103e0f49",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Make sure your function passes the tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f53ac73f1b9e0e25",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(59)\n",
    "r2 = sklearn_r_squared(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(-1.8824436011394203, r2)\n",
    "\n",
    "np.random.seed(5123)\n",
    "r2 = sklearn_r_squared(np.random.rand(10), np.random.rand(10))\n",
    "assert math.isclose(-1.360482238317167, r2)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "r2 = sklearn_adjusted_r_squared(np.random.rand(10), np.random.rand(10), 4)\n",
    "assert math.isclose(-0.45675594806589004, r2)\n",
    "\n",
    "np.random.seed(59)\n",
    "r2 = sklearn_adjusted_r_squared(np.random.rand(10), np.random.rand(10), 2)\n",
    "assert math.isclose(-2.7059989157506834, r2)\n",
    "\n",
    "np.random.seed(5123)\n",
    "r2 = sklearn_adjusted_r_squared(np.random.rand(10), np.random.rand(10), 6)\n",
    "assert math.isclose(-6.081446714951501, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d4eac2c0c131600",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finally, compare the sklearn-based metrics with your own for the housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a640ee4b962fead1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for Housing dataset with base implementation:\n",
      "Mean Absolute Error Housing dataset: 3.270862810900312\n",
      "Mean Squared Error Housing dataset: 21.894831181729206\n",
      "Root Mean Squared Error Housing dataset: 4.679191295697282\n",
      "R² Housing dataset: 0.7406426641094094\n",
      "Adjusted R² Housing dataset: 0.7337897263724629\n",
      "\n",
      "\n",
      "Metric for Housing dataset with scikitlearn:\n",
      "Mean Absolute Error Housing dataset: 3.270862810900312\n",
      "Mean Squared Error Housing dataset: 21.894831181729206\n",
      "Root Mean Squared Error Housing dataset: 4.679191295697282\n",
      "R² Housing dataset: 0.7406426641094094\n",
      "Adjusted R² Housing dataset: 0.7337897263724629\n"
     ]
    }
   ],
   "source": [
    "MAE, _ = mean_absolute_error(y_hat_housing, y_housing)\n",
    "MSE, _ = mean_squared_error(y_hat_housing, y_housing)\n",
    "RMSE = root_mean_squared_error(y_hat_housing, y_housing)\n",
    "R2 = r_squared(y_hat_housing, y_housing)\n",
    "R2_adj = adjusted_r_squared(y_hat_housing, y_housing, x_housing.shape[1])\n",
    "\n",
    "print('Metric for Housing dataset with base implementation:')\n",
    "print('Mean Absolute Error Housing dataset: {}'.format(MAE))\n",
    "print('Mean Squared Error Housing dataset: {}'.format(MSE))\n",
    "print('Root Mean Squared Error Housing dataset: {}'.format(RMSE))\n",
    "print('R² Housing dataset: {}'.format(R2))\n",
    "print('Adjusted R² Housing dataset: {}'.format(R2_adj))\n",
    "print('\\n')\n",
    "\n",
    "SK_MAE = sklearn_mean_absolute_error(y_hat_housing, y_housing)\n",
    "SK_MSE = sklearn_mean_squared_error(y_hat_housing, y_housing)\n",
    "SK_RMSE = sklearn_root_mean_squared_error(y_hat_housing, y_housing)\n",
    "SK_R2 = sklearn_r_squared(y_hat_housing, y_housing)\n",
    "SK_R2_adj = sklearn_adjusted_r_squared(y_hat_housing, y_housing, x_housing.shape[1])\n",
    "\n",
    "print('Metric for Housing dataset with scikitlearn:')\n",
    "print('Mean Absolute Error Housing dataset: {}'.format(SK_MAE))\n",
    "print('Mean Squared Error Housing dataset: {}'.format(SK_MSE))\n",
    "print('Root Mean Squared Error Housing dataset: {}'.format(SK_RMSE))\n",
    "print('R² Housing dataset: {}'.format(SK_R2))\n",
    "print('Adjusted R² Housing dataset: {}'.format(SK_R2_adj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4db11cce9296226a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3 Using the Metrics\n",
    "\n",
    "Now you'll use the metrics to fit and check performance of your LinearRegression and SGDRegressor, with the `cross_val_scores` method of scikitlearn. Implement the missing steps below with the mean squared error metric:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3897cdeea2d9f3c1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "\n",
    "def estimator_cross_fold(X, y, K, clf_choice='linear'):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        X : numpy.array with shape (num_samples, num_features) - sample data\n",
    "        y : numpy.array with shape (num_samples,) - sample labels \n",
    "        K : integer - Number of iterations for k-fold\n",
    "        clf_choice: choice of estimator \n",
    "\n",
    "    Returns: \n",
    "        clf: estimator trained with full data\n",
    "        scores : scores for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    if clf_choice == 'linear':\n",
    "        clf = linear_model.LinearRegression()\n",
    "    elif clf_choice == 'sgd':\n",
    "        clf = linear_model.SGDRegressor()\n",
    "    else:\n",
    "        print('Invalid estimator')\n",
    "        return None\n",
    "     \n",
    "    # 1) Fit linear_model\n",
    "    # YOUR CODE HERE\n",
    "    clf.fit(X,y)\n",
    "    print(X)\n",
    "    # 2) Run k-fold cross validation\n",
    "    # YOUR CODE HERE\n",
    "    scores = cross_val_score(clf, X.reshape(-1, 1), y, cv=K,scoring='neg_mean_squared_error')\n",
    "    print(scores)\n",
    "    return clf, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-022cd5ef7d57584b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now test your implementation in the examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e98a83bdca979b4e",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92403512]\n",
      " [0.15787058]\n",
      " [0.86691508]\n",
      " [0.08415694]\n",
      " [0.57357368]\n",
      " [0.28193977]\n",
      " [0.25628056]\n",
      " [0.56398041]\n",
      " [0.21982335]\n",
      " [0.6486208 ]]\n",
      "[-0.07839893 -0.04592946 -0.01665195]\n",
      "[[0.3557792  0.73828239 0.93726038 0.56189917]\n",
      " [0.51122625 0.1121623  0.69044462 0.88150986]\n",
      " [0.24534467 0.13666349 0.69502094 0.35912699]\n",
      " [0.63931474 0.42729864 0.79991763 0.41236925]\n",
      " [0.21802713 0.71280575 0.85731206 0.22401338]\n",
      " [0.81685184 0.63380045 0.0148524  0.27455112]\n",
      " [0.2704055  0.05155803 0.39305361 0.74699932]\n",
      " [0.94409831 0.22262079 0.25950764 0.05456452]\n",
      " [0.1400195  0.99848186 0.87558146 0.14997049]\n",
      " [0.51089173 0.01034941 0.46092912 0.5855387 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [40, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-14412731c7ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator_cross_fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_choice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_array_almost_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.2097778\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.17224297\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.14589825\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-0ecb78f44aff>\u001b[0m in \u001b[0;36mestimator_cross_fold\u001b[1;34m(X, y, K, clf_choice)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# 2) Run k-fold cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\slu9\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\slu9\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \"\"\"\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\slu9\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\slu9\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [40, 10]"
     ]
    }
   ],
   "source": [
    "np.random.seed(59)\n",
    "_, scores = estimator_cross_fold(np.random.rand(10).reshape((-1, 1)), np.random.rand(10), 3, clf_choice='linear')\n",
    "np.testing.assert_array_almost_equal(np.array([-0.07839893, -0.04592946, -0.01665195]), scores)\n",
    "\n",
    "np.random.seed(5123)\n",
    "_, scores = estimator_cross_fold(np.random.rand(40).reshape((10, 4)), np.random.rand(10), 3, clf_choice='linear')\n",
    "np.testing.assert_array_almost_equal(np.array([-0.2097778, -0.17224297, -0.14589825]), scores)\n",
    "\n",
    "np.random.seed(42)\n",
    "_, scores = estimator_cross_fold(np.random.rand(40).reshape((10, 4)), np.random.rand(10), 5, clf_choice='linear')\n",
    "np.testing.assert_array_almost_equal(np.array([-1.27662973, -0.28584229, -0.08559289, -0.00846645, -0.3445721]), scores)\n",
    "\n",
    "\n",
    "np.random.seed(59)\n",
    "_, scores = estimator_cross_fold(np.random.rand(10).reshape((-1, 1)), np.random.rand(10), 3, clf_choice='sgd')\n",
    "np.testing.assert_array_almost_equal(np.array([-0.16860628, -0.00500938, -0.032316]), scores)\n",
    "\n",
    "np.random.seed(5123)\n",
    "_, scores = estimator_cross_fold(np.random.rand(40).reshape((10, 4)), np.random.rand(10), 3, clf_choice='sgd')\n",
    "np.testing.assert_array_almost_equal(np.array([-0.09693064, -0.15065178, -0.03216094]), scores)\n",
    "\n",
    "np.random.seed(42)\n",
    "_, scores = estimator_cross_fold(np.random.rand(40).reshape((10, 4)), np.random.rand(10), 5, clf_choice='sgd')\n",
    "np.testing.assert_array_almost_equal(np.array([-0.0564828, -0.26257013, -0.09163569, -0.03838608, -0.03581247]), scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcc3f2c444820d21",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's check the performance a dataset of linear data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c975af75352c7e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25723e07eb8>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "linear_data = pd.read_csv('data/linear.csv')\n",
    "linear_data = linear_data.sort_values('x')\n",
    "\n",
    "x = linear_data['x'].values.reshape(-1, 1)\n",
    "y = linear_data['y'].values.reshape(-1, 1)\n",
    "\n",
    "plt.plot(x, y, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b40e60f00f4f1fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the k-fold cross validation for both regressors and get the average error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5565c9de30569d21",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "clf_lr, scores_lr = estimator_cross_fold(x, y, 5, clf_choice='linear')\n",
    "assert math.isclose(-7.907250808383319, scores_lr.mean())\n",
    "\n",
    "clf_sgd, scores_sgd = estimator_cross_fold(x, y.flatten(), 5, clf_choice='sgd')\n",
    "assert math.isclose(-7.653262471797137, scores_sgd.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-caf92b1ed53ac1bc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We would conclude then that the SGDRegressor is better for this data in estimating unseen examples. This does not mean that the error for all data will be smaller, but it means that when holding out data, the SGDRegressor is slightly better at classifying new examples. Actually, both estimators for this particular use case are quite similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e271580b32a9a9f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_hat_linear = clf_lr.predict(x)\n",
    "y_hat_sgd = clf_sgd.predict(x)\n",
    "\n",
    "plt.plot(x, y, 'b.')\n",
    "plt.plot(x, y_hat_linear, 'r-')\n",
    "plt.plot(x, y_hat_sgd, 'g-')\n",
    "\n",
    "print('Error for full dataset for linear regressor: {}'.format(sklearn_mean_squared_error(y_hat_linear, y)))\n",
    "print('Error for full dataset for SGD: {}'.format(sklearn_mean_squared_error(y_hat_sgd, y)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
